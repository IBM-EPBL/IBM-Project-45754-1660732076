# -*- coding: utf-8 -*-
"""Assignment 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lh_UZ4_GPeVXA1MOMktNnTkWS8WPAGIZ

#Download the dataset
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
sns.set_style('darkgrid')
sns.set(font_scale=1.3)

"""#Uploaded the dataset"""

df=pd.read_csv("/content/Churn_Modelling.csv")
df

"""#Load the given dataset"""

df.tail()

"""#Perform Below Visualizations

###1.Univariate Analysis
"""

sns.displot(df.Balance)

"""###2.Bivariate Analysis"""

df.plot.line()

"""###3.Multivariate Analysis"""

sns.lmplot("Tenure","NumOfProducts",df,hue="NumOfProducts", fit_reg=False);

"""#Perform descriptive statistics on the dataset"""

df.describe()

"""#Handle the Missing values """

data = pd.read_csv("Churn_Modelling.csv")
pd.isnull(data["HasCrCard"])

"""#Find the Outliers and replace the outliers"""

df["IsActiveMember"] = np.where(df["IsActiveMember"] >10, np.median,df["IsActiveMember"])
df["IsActiveMember"]

"""#Check for Categorial columns and perform encoding"""

pd.get_dummies(df, columns=["Gender", "CreditScore"], prefix=["CreditScore", "Gender"]).tail()

"""#Split the data into dependent and independent variables"""

X = df.iloc[:, :-1].values
print(X)

Y = df.iloc[:, -2].values
print(Y)

"""#Scale the independent variables"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[["Balance"]] = scaler.fit_transform(df[["Balance"]])
print(df)

"""#Split the data into training and testing"""

from sklearn.model_selection import train_test_split
train_size=0.8
X = df.drop(columns = ['RowNumber']).copy()
y = df['RowNumber']
X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)
test_size = 0.5
X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)
print(X_train.shape), print(y_train.shape)
print(X_valid.shape), print(y_valid.shape)
print(X_test.shape), print(y_test.shape)